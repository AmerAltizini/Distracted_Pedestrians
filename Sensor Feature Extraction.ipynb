{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os.path\n",
    "import warnings\n",
    "from os.path import exists\n",
    "import pandas as pd\n",
    "from src.OfflineSlidingWindow import sliding_window\n",
    "from src.ExtractFeatures import compute_features\n",
    "\n",
    "# from PreprocessSignals import preprocessing_EDA, processing_labels, preprocessing_BVP, select_data\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# set parameter\n",
    "windowLength = 5 * 1000  # unit milliseconds\n",
    "overlap = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "----------\n",
    "# Run Feature Extraction for Distracted Pedestrians data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "path_sensor = \"./Data/input/\"\n",
    "sensors = ['Accelerometer']\n",
    "inputs = []"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AR\n"
     ]
    },
    {
     "data": {
      "text/plain": "            time     lux\n0   1.670789e+18  0.0000\n1   1.670789e+18  1.4125\n2   1.670789e+18  2.9875\n3   1.670789e+18  4.4125\n4   1.670789e+18  9.1125\n5   1.670789e+18  0.0000\n6   1.670789e+18  2.5250\n7   1.670789e+18  0.0000\n8   1.670789e+18  2.8000\n9   1.670789e+18  0.0000\n10  1.670789e+18  5.1375\n11  1.670789e+18  1.2625\n12  1.670789e+18  3.3125\n13  1.670789e+18  1.8875\n14  1.670789e+18  0.0000\n15  1.670789e+18  1.4125",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>time</th>\n      <th>lux</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.670789e+18</td>\n      <td>0.0000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.670789e+18</td>\n      <td>1.4125</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.670789e+18</td>\n      <td>2.9875</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.670789e+18</td>\n      <td>4.4125</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.670789e+18</td>\n      <td>9.1125</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1.670789e+18</td>\n      <td>0.0000</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1.670789e+18</td>\n      <td>2.5250</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1.670789e+18</td>\n      <td>0.0000</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1.670789e+18</td>\n      <td>2.8000</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1.670789e+18</td>\n      <td>0.0000</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>1.670789e+18</td>\n      <td>5.1375</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>1.670789e+18</td>\n      <td>1.2625</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>1.670789e+18</td>\n      <td>3.3125</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>1.670789e+18</td>\n      <td>1.8875</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>1.670789e+18</td>\n      <td>0.0000</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>1.670789e+18</td>\n      <td>1.4125</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "['Light']"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "error_protocol = []\n",
    "\n",
    "# run through all participants here\n",
    "for participant_filepath in glob.iglob(path_sensor + \"AR/\", recursive=True):\n",
    "    try:\n",
    "        components = os.path.normpath(participant_filepath)\n",
    "        components = components.split(os.path.sep)\n",
    "        participant = components[-1]\n",
    "        print(participant)\n",
    "\n",
    "        # read in labels\n",
    "        ground_truth = pd.read_csv('{}Annotation.csv'.format(participant_filepath))\n",
    "        ground_truth['time'] = ground_truth['time'].astype('float64')\n",
    "        ground_truth.set_index('time', inplace=True)\n",
    "\n",
    "        # get information when HRI began and stopped for sliding window\n",
    "        start_ts = ground_truth.first_valid_index()\n",
    "        end_ts = ground_truth.last_valid_index()\n",
    "\n",
    "        # variable to store extracted features\n",
    "        extractedFeatures = pd.DataFrame()\n",
    "        # run through single sensors\n",
    "        flag = True\n",
    "        for sensor in sensors:\n",
    "            # check if filesize empty\n",
    "            if os.stat(participant_filepath + sensor + \".csv\").st_size == 0: continue\n",
    "\n",
    "            # read in sensor data\n",
    "            sensor_data = pd.read_csv(participant_filepath + sensor + \".csv\")\n",
    "            sensor_data['time'] = sensor_data['time'].astype('float64')\n",
    "            sensor_data = sensor_data.drop(['seconds_elapsed'], axis=1)\n",
    "            display(sensor_data)\n",
    "            # use only E4 data needed\n",
    "            sensor_data = sensor_data[(sensor_data.time >= start_ts) & (sensor_data.time <= end_ts)]\n",
    "\n",
    "            #check if dataframe is empty\n",
    "            if sensor_data.empty:\n",
    "                continue\n",
    "            sensor_data.set_index('time', inplace=True)  # drop=False?\n",
    "            # within this notfication do windowing and calculate features\n",
    "            column = []\n",
    "            if sensor == \"Accelerometer\":\n",
    "                column = ['x', 'y', 'z']\n",
    "            elif sensor == \"Gyroscope\":\n",
    "                column = ['x', 'y', 'z']\n",
    "            else:\n",
    "                column = [str(sensor)]\n",
    "            # start feature extraction\n",
    "            display(column)\n",
    "            result = sliding_window(sensor_data, column, windowLength, overlap, start_ts)\n",
    "            # create one big dataframe containing all sensor data\n",
    "            # if flag:\n",
    "            #     extractedFeatures = result\n",
    "            #     flag = False\n",
    "            # else:\n",
    "            #     extractedFeatures = pd.merge_ordered(extractedFeatures, result, on=['window_ts'], how='outer')\n",
    "            extractedFeatures.to_csv(participant_filepath + participant + \"_features.csv\", sep=',', index=False)\n",
    "            print(participant_filepath)\n",
    "\n",
    "    except:\n",
    "        error_protocol.append(participant_filepath)\n",
    "        continue"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AR\n"
     ]
    },
    {
     "data": {
      "text/plain": "            time     lux\n0   1.670789e+18  0.0000\n1   1.670789e+18  1.4125\n2   1.670789e+18  2.9875\n3   1.670789e+18  4.4125\n4   1.670789e+18  9.1125\n5   1.670789e+18  0.0000\n6   1.670789e+18  2.5250\n7   1.670789e+18  0.0000\n8   1.670789e+18  2.8000\n9   1.670789e+18  0.0000\n10  1.670789e+18  5.1375\n11  1.670789e+18  1.2625\n12  1.670789e+18  3.3125\n13  1.670789e+18  1.8875\n14  1.670789e+18  0.0000\n15  1.670789e+18  1.4125",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>time</th>\n      <th>lux</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.670789e+18</td>\n      <td>0.0000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.670789e+18</td>\n      <td>1.4125</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.670789e+18</td>\n      <td>2.9875</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.670789e+18</td>\n      <td>4.4125</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.670789e+18</td>\n      <td>9.1125</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1.670789e+18</td>\n      <td>0.0000</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1.670789e+18</td>\n      <td>2.5250</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1.670789e+18</td>\n      <td>0.0000</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1.670789e+18</td>\n      <td>2.8000</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1.670789e+18</td>\n      <td>0.0000</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>1.670789e+18</td>\n      <td>5.1375</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>1.670789e+18</td>\n      <td>1.2625</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>1.670789e+18</td>\n      <td>3.3125</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>1.670789e+18</td>\n      <td>1.8875</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>1.670789e+18</td>\n      <td>0.0000</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>1.670789e+18</td>\n      <td>1.4125</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "['Light']"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "error_protocol = []\n",
    "\n",
    "# run through all participants here\n",
    "for participant_filepath in glob.iglob(path_sensor + \"AR/\", recursive=True):\n",
    "    try:\n",
    "        components = os.path.normpath(participant_filepath)\n",
    "        components = components.split(os.path.sep)\n",
    "        participant = components[-1]\n",
    "        print(participant)\n",
    "\n",
    "        # read in labels\n",
    "        ground_truth = pd.read_csv('{}Annotation.csv'.format(participant_filepath))\n",
    "        ground_truth['time'] = ground_truth['time'].astype('float64')\n",
    "        ground_truth.set_index('time', inplace=True)\n",
    "\n",
    "        # get information when HRI began and stopped for sliding window\n",
    "        start_ts = ground_truth.first_valid_index()\n",
    "        end_ts = ground_truth.last_valid_index()\n",
    "\n",
    "        # variable to store extracted features\n",
    "        extractedFeatures = pd.DataFrame()\n",
    "        # run through single sensors\n",
    "        flag = True\n",
    "        for sensor in sensors:\n",
    "            # check if filesize empty\n",
    "            if os.stat(participant_filepath + sensor + \".csv\").st_size == 0: continue\n",
    "\n",
    "            # read in sensor data\n",
    "            sensor_data = pd.read_csv(participant_filepath + sensor + \".csv\")\n",
    "            sensor_data['time'] = sensor_data['time'].astype('float64')\n",
    "            sensor_data = sensor_data.drop(['seconds_elapsed'], axis=1)\n",
    "            display(sensor_data)\n",
    "            # use only E4 data needed\n",
    "            sensor_data = sensor_data[(sensor_data.time >= start_ts) & (sensor_data.time <= end_ts)]\n",
    "\n",
    "            #check if dataframe is empty\n",
    "            if sensor_data.empty:\n",
    "                continue\n",
    "            sensor_data.set_index('time', inplace=True)  # drop=False?\n",
    "            # within this notfication do windowing and calculate features\n",
    "            column = []\n",
    "            if sensor == \"Accelerometer\":\n",
    "                column = ['x', 'y', 'z']\n",
    "            elif sensor == \"Gyroscope\":\n",
    "                column = ['x', 'y', 'z']\n",
    "            else:\n",
    "                column = [str(sensor)]\n",
    "            # start feature extraction\n",
    "            display(column)\n",
    "\n",
    "            # if sensor_data.shape[0] < 1:\n",
    "            #     continue\n",
    "            # if type(overlap) != type(0.0) or type(windowLength) != type(0):\n",
    "            #     raise Exception('**Error** type(overlap) must be float and type(windowsize) must be int')\n",
    "            # if overlap > windowLength:\n",
    "            #     raise Exception('**Error** overlap is larger than windowsize...')\n",
    "            #\n",
    "            # if \"lux\" in column:\n",
    "            #     # Creating chunks\n",
    "            #     suffix = ['slope', 'sqrtSlope', 'sqrtIntersect', 'thirdSqrtIntersect']\n",
    "            #     header1 = ['{}_{}'.format(col, suf) for col in column for suf in suffix]\n",
    "            #     suffix = ['var', 'std', 'skew', 'rms', 'min', 'max', 'mean', 'median']\n",
    "            #     header2 = ['{}_{}'.format(col, suf) for col in column for suf in suffix]\n",
    "            #     header = header1 + header2 + ['window_ts']\n",
    "            #\n",
    "            # if  label:\n",
    "            #     header =  header + [\"label\"]\n",
    "            #\n",
    "            # result = pd.DataFrame(columns=header)\n",
    "            #\n",
    "            # # set timing parameters\n",
    "            # # step is the time the window slides forward\n",
    "            # step = int(windowLength * (1 - overlap))\n",
    "            # if start_ts != None:\n",
    "            #     start = start_ts\n",
    "            # else:\n",
    "            #     start = sensor_data['time'].iloc[0]\n",
    "            # # grap last instance of dataset as end time\n",
    "            # end = sensor_data.last_valid_index()\n",
    "            #\n",
    "            # # get windows\n",
    "            # while start < end:\n",
    "            #     row_result = []\n",
    "            #     window = sensor_data[(sensor_data.index >= start) & (start + windowLength >= sensor_data.index)]\n",
    "            #\n",
    "            #     # does window contain data\n",
    "            #     if window.shape[0] > 1:  # needs more than one element in window\n",
    "            #         if 'lux' in column:\n",
    "            #             # row_result = get_IBI_features(window)\n",
    "            #             row_result['window_ts'] = start\n",
    "            #             # labels - labels hinzufügen\n",
    "            #             if label:\n",
    "            #                 row_result.append(pd.value_counts(window['label']).idxmax())\n",
    "            #             result = result.append(row_result)\n",
    "            #         else:\n",
    "            #             # start statistical feature calculation\n",
    "            #             row_result = compute_features(window, column)\n",
    "            #             row_result.append(start)\n",
    "            #             # labels - labels hinzufügen\n",
    "            #             if label:\n",
    "            #                 row_result.append(pd.value_counts(window['label']).idxmax())\n",
    "            #             # add window to final result\n",
    "            #             result.loc[len(result)] = row_result\n",
    "            #     start = start + step\n",
    "            # return result\n",
    "            result = sliding_window(sensor_data, column, windowLength, overlap, start_ts)\n",
    "            # create one big dataframe containing all sensor data\n",
    "            if flag:\n",
    "                extractedFeatures = result\n",
    "                flag = False\n",
    "            else:\n",
    "                extractedFeatures = pd.merge_ordered(extractedFeatures, result, on=['window_ts'], how='outer')\n",
    "            extractedFeatures.to_csv(participant_filepath + participant + \"_features.csv\", sep=',', index=False)\n",
    "            print(participant_filepath)\n",
    "\n",
    "    except:\n",
    "        error_protocol.append(participant_filepath)\n",
    "        continue"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "path_sensor = \"./Data/input/\"\n",
    "sensors = ['Accelerometer']\n",
    "inputs = []\n",
    "# set parameter\n",
    "windowLength = 5 * 10  # unit milliseconds\n",
    "overlap = 0.5"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "error_protocol = []\n",
    "\n",
    "# run through all participants here\n",
    "for participant_filepath in glob.iglob(path_sensor + \"AR/\", recursive=True):\n",
    "    try:\n",
    "        components = os.path.normpath(participant_filepath)\n",
    "        components = components.split(os.path.sep)\n",
    "        participant = components[-1]\n",
    "        print(participant)\n",
    "\n",
    "        # read in labels\n",
    "        ground_truth = pd.read_csv('{}Annotation.csv'.format(participant_filepath))\n",
    "        ground_truth['time'] = ground_truth['time'].astype('float64')\n",
    "        ground_truth.set_index('time', inplace=True)\n",
    "\n",
    "        # get information when HRI began and stopped for sliding window\n",
    "        start_ts = ground_truth.first_valid_index()\n",
    "        end_ts = ground_truth.last_valid_index()\n",
    "\n",
    "        # variable to store extracted features\n",
    "        extractedFeatures = pd.DataFrame()\n",
    "        # run through single sensors\n",
    "        flag = True\n",
    "        for sensor in sensors:\n",
    "            # check if filesize empty\n",
    "            if os.stat(participant_filepath + sensor + \".csv\").st_size == 0: continue\n",
    "\n",
    "            # read in sensor data\n",
    "            sensor_data = pd.read_csv(participant_filepath + sensor + \".csv\")\n",
    "            sensor_data['time'] = sensor_data['time'].astype('float64')\n",
    "            sensor_data = sensor_data.drop(['seconds_elapsed'], axis=1)\n",
    "            # display(sensor_data)\n",
    "            # use only E4 data needed\n",
    "            sensor_data = sensor_data[(sensor_data.time >= start_ts) & (sensor_data.time <= end_ts)]\n",
    "\n",
    "            #check if dataframe is empty\n",
    "            if sensor_data.empty:\n",
    "                continue\n",
    "            sensor_data.set_index('time', inplace=True)  # drop=False?\n",
    "            # within this notfication do windowing and calculate features\n",
    "            column = []\n",
    "            if sensor == \"Accelerometer\":\n",
    "                column = ['x', 'y', 'z']\n",
    "            elif sensor == \"Gyroscope\":\n",
    "                column = ['x', 'y', 'z']\n",
    "            else:\n",
    "                column = [str(sensor)]\n",
    "            # start feature extraction\n",
    "            # display(column)\n",
    "            segments = sensor_data.rolling(window=windowLength, center=True).agg(['min', 'max', 'sum', 'mean', 'std'])\n",
    "            segments.columns = ['-'.join(tup).rstrip('-') for tup in segments.columns.values]\n",
    "            segments = pd.concat([sensor_data.iloc[:, -1], segments], axis=1)\n",
    "            # segments = segments.dropna()\n",
    "            # segments = segments[::(int)(window_size * overlap)]\n",
    "            percentage = (int)((windowLength)-(windowLength * overlap))\n",
    "            segments = segments[::percentage]\n",
    "            extractedFeatures = segments\n",
    "            display(extractedFeatures)\n",
    "            # result = sliding_window(sensor_data, column, windowLength, overlap, start_ts)\n",
    "            # create one big dataframe containing all sensor data\n",
    "            # if flag:\n",
    "            #     extractedFeatures = result\n",
    "            #     flag = False\n",
    "            # else:\n",
    "            #     extractedFeatures = pd.merge_ordered(features_df, result, on=['time'], how='outer')\n",
    "            extractedFeatures.to_csv(participant_filepath + participant + \"_features.csv\", sep=',', index=False)\n",
    "            # print(participant_filepath)\n",
    "\n",
    "    except:\n",
    "        error_protocol.append(participant_filepath)\n",
    "        continue"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of Features: 561\n"
     ]
    }
   ],
   "source": [
    "# get feature names from the file features.txt\n",
    "features = list()\n",
    "with open('Data/features.txt') as f:\n",
    "    features = [line.split()[1] for line in f.readlines()]\n",
    "\n",
    "print('No of Features: {}'.format(len(features)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "561"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seen = set()\n",
    "uniq_features = []\n",
    "for idx, x in enumerate(features):\n",
    "    if x not in seen:\n",
    "        uniq_features.append(x)\n",
    "        seen.add(x)\n",
    "    elif x + 'n' not in seen:\n",
    "        uniq_features.append(x + 'n')\n",
    "        seen.add(x + 'n')\n",
    "    else:\n",
    "        uniq_features.append(x + 'nn')\n",
    "        seen.add(x + 'nn')\n",
    "len(uniq_features)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# https://github.com/arijitiiest/UCI-Human-Activity-Recognition/blob/master/Data-preprocessing.ipynb"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
